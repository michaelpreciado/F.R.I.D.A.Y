version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]   # ignored on Mac, used on Linux/NVIDIA

  api:
    build:
      context: .
      dockerfile: ./backend/Dockerfile
      args:
        MODE: ${MODE:-local}
    environment:
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - MODEL_TAG=${MODEL_TAG:-deepseek-r1:7b}
      - PERSONALITY_SYSTEM_PROMPT=${PERSONALITY_SYSTEM_PROMPT:-"You are a helpful AI."}
      - ELEVENLABS_VOICE_ID=${ELEVENLABS_VOICE_ID:-21m00Tcm4TlvDq8ikWAM}
    ports:
      - "${LOCAL_PORT:-8000}:8000"
    depends_on:
      - ollama

volumes:
  ollama-data: {}
